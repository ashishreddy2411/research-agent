# Deep Research Agent â€” Built in Raw Python

> A complete, working Deep Research Agent built without any agent framework â€” giving you full visibility and control over every layer of the system.

---

## What This Project Is

A system that takes a plain English question, plans a research strategy, searches the web, reads pages, compresses context, reflects on gaps, searches again, and synthesizes a cited structured report.

Built entirely in raw Python. No LangChain. No LangGraph. No GPT-Researcher. Every component â€” the research loop, the reflect-search iteration, the context compression, the synthesis pipeline â€” is written from scratch. No framework hiding what's actually happening.

---

## What This Covers

**Core capabilities:**

| Concept | How it works here |
|---|---|
| Planning | Planner decomposes question into targeted subqueries |
| Tools | search, fetch, extract, summarize â€” each a clean isolated module |
| Input type | Unstructured HTML and web pages |
| Context management | 50-100 pages compressed via cheap model + relevance filter |
| Stopping condition | Reflector decides when coverage is sufficient |
| Output | Multi-section report with inline citations |
| Cost control | Hard cap â€” research runs are unbounded without it |

**Production patterns (Phase 6):**
- Job queue: decouple submission from execution
- Checkpoint + resume: never lose work to a crash
- Hard cost cap: ceiling on unbounded LLM spend
- Timeout + graceful degradation: one slow URL never blocks everything
- Streaming progress events: tell the user what's happening in real time

---

## Architecture

```
User Question
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Planner                         â”‚
â”‚  LLM decomposes into 3-5 queries â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Research Loop                                          â”‚
â”‚                                                         â”‚
â”‚  Round 1: asyncio.gather(                              â”‚
â”‚    Researcher(subquery_1),  â† parallel                 â”‚
â”‚    Researcher(subquery_2),  â† parallel                 â”‚
â”‚    Researcher(subquery_3),  â† parallel                 â”‚
â”‚  )                                                      â”‚
â”‚                                                         â”‚
â”‚  Each Researcher:                                       â”‚
â”‚    tavily.search(query) â†’ URLs + page content          â”‚
â”‚    cheap_llm.summarize(page) â†’ 200-word bullets        â”‚
â”‚                                                         â”‚
â”‚  Reflector: "What gaps remain? Follow-up query?"       â”‚
â”‚    â†’ gap found â†’ Round 2 with new targeted query       â”‚
â”‚    â†’ no gap OR max rounds â†’ stop                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Context Filter                  â”‚
â”‚  cosine_similarity(question,     â”‚
â”‚    each summary) â†’ top 20        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Synthesizer                     â”‚
â”‚  Outline â†’ section by section    â”‚
â”‚  Inline citations [1][2]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
    ResearchState returned
    (report, sources, cost_usd, rounds, status)
```

---

## Project Structure

```
research-agent/
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ state.py          # ResearchState dataclass + ResearchStatus enum
â”‚   â”œâ”€â”€ planner.py        # query decomposition â€” one question â†’ N subqueries
â”‚   â”œâ”€â”€ researcher.py     # search + fetch + summarize for one subquery
â”‚   â”œâ”€â”€ reflector.py      # gap detection â€” should we search again?
â”‚   â”œâ”€â”€ synthesizer.py    # outline + section-by-section report generation
â”‚   â””â”€â”€ loop.py           # orchestrates the full research pipeline
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ search.py         # Tavily API wrapper â†’ list[SearchResult]
â”‚   â”œâ”€â”€ fetch.py          # Jina Reader + trafilatura â†’ FetchResult
â”‚   â””â”€â”€ extract.py        # HTML â†’ clean text, truncation helpers
â”‚
â”œâ”€â”€ llm/
â”‚   â””â”€â”€ client.py         # Azure Foundry wrapper: generate, generate_cheap, embed
â”‚
â”œâ”€â”€ observability/
â”‚   â””â”€â”€ tracer.py         # Span + Trace structured logging (from SQL Agent)
â”‚
â”œâ”€â”€ evals/
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â””â”€â”€ golden.jsonl  # 20 research questions with expected topics
â”‚   â”œâ”€â”€ runner.py         # runs evals against real LLM
â”‚   â””â”€â”€ metrics.py        # coverage metric, source quality metric
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/             # pure logic tests, no API calls
â”‚   â””â”€â”€ integration/      # end-to-end tests with real APIs
â”‚
â”œâ”€â”€ config.py             # pydantic-settings â€” all env vars typed + validated
â”œâ”€â”€ app.py                # Streamlit UI (Phase 5)
â”œâ”€â”€ pyproject.toml
â””â”€â”€ .env.example
```

---

## Setup

### Prerequisites
- Python 3.12+
- [uv](https://docs.astral.sh/uv/) installed
- Microsoft Azure AI Foundry project with models deployed
- Tavily API key (free at [app.tavily.com](https://app.tavily.com))

### Models needed in Azure Foundry
| Role | Model | Used for |
|---|---|---|
| Smart | `gpt-5.2-chat` | Planning, reflection, synthesis |
| Cheap | `gpt-4o-mini` | Per-page summarization (50-100x per run) |
| Embeddings | `text-embedding-3-small` | Context relevance filtering |

### Install

```bash
cd research-agent
uv sync
```

### Configure

```bash
cp .env.example .env
# Edit .env with your credentials
```

### Run unit tests (no API keys needed)

```bash
uv run pytest tests/unit/ -v
```

### Run integration test (needs real API keys)

```bash
uv run python tests/integration/test_phase1_tools.py
```

---

## Build Status

| Phase | Status | What it builds |
|---|---|---|
| 1 â€” Foundation | âœ… Complete | Search, fetch, extract tools |
| 2 â€” Research Loop | ğŸ”² | Planner, researcher, reflector, ResearchState |
| 3 â€” Synthesis + Report | ğŸ”² | Section-by-section report, citations |
| 4 â€” Evals + Observability | ğŸ”² | Coverage metrics, cost tracking, traces |
| 5 â€” Parallel Fetching + UI | ğŸ”² | asyncio fan-out, Streamlit |
| 6 â€” Production Ready | ğŸ”² | Job queue, checkpoints, cost cap, streaming |

---

## Tech Stack

| Layer | Tool |
|---|---|
| LLM | GPT-5.2 + GPT-4o-mini via Microsoft Azure AI Foundry |
| Search | Tavily API |
| URL fetching | Jina Reader + trafilatura |
| Agent framework | Raw Python â€” no LangChain, no LangGraph |
| Config | `pydantic-settings` v2 |
| Web UI | Streamlit (Phase 5) |
| Package manager | `uv` |
| Tests | `pytest` |

---

*Last updated: February 2026*
